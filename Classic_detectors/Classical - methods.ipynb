{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import time as tm\n",
    "import math\n",
    "import sys\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "# from gurobipy import *\n",
    "from multiprocessing.dummy import Pool as ThreadPool \n",
    "from numpy import linalg as LA\n",
    "from classic_detectors import *\n",
    "from sample_generator import *\n",
    "from utils import *\n",
    "import os *\n",
    "\n",
    "#parameters\n",
    "NT = 2\n",
    "NR = 4\n",
    "\n",
    "snrdb_list = {16:np.arange(5.0, 15.0), 2:np.arange(5.0, 15.0), 6:np.arange(10.0, 21.0)}\n",
    "mod_n = 4\n",
    "\n",
    "corr_flag = True\n",
    "batch_corr = True\n",
    "batch_size = 100\n",
    "time_seq = 5\n",
    "\n",
    "parallel = False\n",
    "\n",
    "M = int(np.sqrt(mod_n))\n",
    "sigConst = np.linspace(-M+1, M-1, M) \n",
    "sigConst /= np.sqrt((sigConst ** 2).mean())\n",
    "sigConst /= np.sqrt(2.) ",
    "PATH = os.getcwd()",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZF(NT, snr_min, snr_max, batch_size, repeat_sample, generator, device, Cu = None, H = None, iterations = 50):\n",
    "    SNR_dBs = np.linspace(np.int(snr_min), np.int(snr_max), np.int(snr_max - snr_min + 1))\n",
    "    accs_NN = []#np.zeros(shape=SNR_dBs.shape)\n",
    "    real_QAM_const = generator.real_QAM_const.to(device=device)\n",
    "    imag_QAM_const = generator.imag_QAM_const.to(device=device)\n",
    "    bs = batch_size * repeat_sample\n",
    "    H = torch.tensor(H)\n",
    "    H = H.repeat_interleave(repeat_sample, dim=0)\n",
    "    for i in range(SNR_dBs.shape[0]):\n",
    "        acum = 0\n",
    "        print(i)\n",
    "        for jj in range(iterations):\n",
    "            rho = 0.6\n",
    "            y, x, j_indices, noise_sigma = generator.give_batch_data_Hinput(H, NT, snr_db_min=SNR_dBs[i], snr_db_max=SNR_dBs[i], batch_size=batch_size)\n",
    "\n",
    "            H = H.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            x = x.to(device=device)\n",
    "            j_indices = j_indices.to(device=device)      \n",
    "            noise_sigma = noise_sigma.to(device=device)\n",
    "\n",
    "            y_ZF = batch_matvec_mul(torch.pinverse(H).double(), y.double())\n",
    "\n",
    "            SER_final = sym_detection(y_ZF, j_indices, real_QAM_const, imag_QAM_const)\n",
    "            acum += SER_final\n",
    "        acum = acum/iterations\n",
    "        accs_NN.append((SNR_dBs[i], 1. - acum))# += acc[1]/iterations\n",
    "        print([SNR_dBs[i], 1. - acum])\n",
    "\n",
    "    return accs_NN\n",
    "\n",
    "def MMSE(NT, snr_min, snr_max, batch_size, repeat_sample, generator, device, Cu = None, H=None, iterations = 50):\n",
    "    SNR_dBs = np.linspace(np.int(snr_min), np.int(snr_max), np.int(snr_max - snr_min + 1))\n",
    "    accs_NN = []\n",
    "    real_QAM_const = generator.real_QAM_const.to(device=device)\n",
    "    imag_QAM_const = generator.imag_QAM_const.to(device=device)\n",
    "    bs = repeat_sample * batch_size\n",
    "\n",
    "    H = torch.tensor(H)\n",
    "    H = H.repeat_interleave(repeat_sample, dim=0)\n",
    "    for i in range(SNR_dBs.shape[0]):\n",
    "        acum = 0\n",
    "        print(i)\n",
    "        for jj in range(iterations):\n",
    "            y, x, j_indices, noise_sigma = generator.give_batch_data_Hinput(H, NT, snr_db_min=SNR_dBs[i], snr_db_max=SNR_dBs[i], batch_size=bs)\n",
    "\n",
    "\n",
    "            H = H.to(device=device).double()\n",
    "            y = y.to(device=device).double()\n",
    "            x = x.to(device=device).double()\n",
    "            j_indices = j_indices.to(device=device).double()        \n",
    "            noise_sigma = noise_sigma.to(device=device).double()\n",
    "\n",
    "            y_MMSE = mmse(y, H, noise_sigma, device).double()\n",
    "\n",
    "            SER_final = sym_detection(y_MMSE, j_indices, real_QAM_const, imag_QAM_const)\n",
    "            acum += SER_final\n",
    "        acum = acum/iterations\n",
    "        accs_NN.append((SNR_dBs[i], 1. - acum))\n",
    "        print([SNR_dBs[i], 1. - acum])\n",
    "        \n",
    "    return accs_NN\n",
    "\n",
    "\n",
    "def ML(NT, snr_min, snr_max, batch_size, repeat_sample, generator, device, Cu = None, H=None, iterations = 500):\n",
    "    SNR_dBs = np.linspace(np.int(snr_min), np.int(snr_max), np.int(snr_max - snr_min + 1))\n",
    "    accs_NN = []#np.zeros(shape=SNR_dBs.shape)\n",
    "    real_QAM_const = generator.real_QAM_const.to(device=device)\n",
    "    imag_QAM_const = generator.imag_QAM_const.to(device=device)\n",
    "    #num_cores = multiprocessing.cpu_count()\n",
    "    pool = ThreadPool(40) \n",
    "    bs = repeat_sample * batch_size\n",
    "    H = H.repeat_interleave(repeat_sample, dim=0)\n",
    "    for i in range(SNR_dBs.shape[0]):\n",
    "        acum = 0\n",
    "        print(i)\n",
    "        for jj in range(iterations):\n",
    "            H = torch.tensor(H)\n",
    "            y, x, j_indices, noise_sigma = generator.give_batch_data_Hinput(H_test, NT, snr_db_min=SNR_dBs[i], snr_db_max=SNR_dBs[i], batch_size = bs)\n",
    "            rho = 0.6\n",
    "\n",
    "            j_indices = j_indices.to(device=device)  \n",
    "            y = y.to(device='cpu').unsqueeze(dim=-1).numpy()\n",
    "            H = H.to(device='cpu').numpy()\n",
    "            const = generator.constellation\n",
    "            if parallel:\n",
    "                shatBatch = pool.map(ml_proc_star, zip(hBatch, yBatch))\n",
    "            else:\n",
    "                shatBatch, status = mlSolver(H, y, sigConst)\n",
    "            SER_final = sym_detection(torch.from_numpy(np.array(shatBatch)).to(device=device).double(), j_indices, real_QAM_const, imag_QAM_const)\n",
    "            acum += SER_final\n",
    "            del y, x, j_indices, noise_sigma\n",
    "        acum = acum/iterations\n",
    "        accs_NN.append((SNR_dBs[i], 1. - acum))# += acc[1]/iterations\n",
    "        print([SNR_dBs[i], 1. - acum])\n",
    "\n",
    "    return accs_NN                    \n",
    "\n",
    "def sym_detection(x_hat, j_indices, real_QAM_const, imag_QAM_const):\n",
    "    x_real, x_imag = torch.chunk(x_hat, 2, dim=-1)\n",
    "    x_real = x_real.unsqueeze(dim=-1).expand(-1,-1, real_QAM_const.numel())\n",
    "    x_imag = x_imag.unsqueeze(dim=-1).expand(-1, -1, imag_QAM_const.numel())\n",
    "\n",
    "    x_real = torch.pow(x_real - real_QAM_const, 2)\n",
    "    x_imag = torch.pow(x_imag - imag_QAM_const, 2)\n",
    "    x_dist = x_real + x_imag\n",
    "    x_indices = torch.argmin(x_dist, dim=-1)\n",
    "\n",
    "    accuracy = (x_indices == j_indices).sum().to(dtype=torch.float32)\n",
    "    return accuracy.item()/j_indices.numel()\n",
    "\n",
    "\n",
    "def batch_matvec_mul(A,b):\n",
    "    '''Multiplies a matrix A of size batch_sizexNxK\n",
    "       with a vector b of size batch_sizexK\n",
    "       to produce the output of size batch_sizexN\n",
    "    '''    \n",
    "    C = torch.matmul(A, torch.unsqueeze(b, dim=2))\n",
    "    return torch.squeeze(C, -1) \n",
    "\n",
    "def batch_identity_matrix(row, cols, batch_size):\n",
    "    eye = torch.eye(row, cols)\n",
    "    eye = eye.reshape((1, row, cols))\n",
    "    \n",
    "    return eye.repeat(batch_size, 1, 1)\n",
    "\n",
    "def batch_trace(H):\n",
    "    return H.diagonal(offset=0, dim1=-1, dim2=-2).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_576127/2037419828.py:103: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  SNR_dBs = np.linspace(np.int(snr_min), np.int(snr_max), np.int(snr_max - snr_min + 1))\n",
      "/tmp/ipykernel_576127/2037419828.py:118: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  H = torch.tensor(H)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_576127/3718568848.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0maccs_ZF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0maccs_ZF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_eval_ML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnrdb_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnrdb_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;31m# accs_ML = model_eval_ML(NT, snrdb_list[NT][0], snrdb_list[NT][-1], 1, repeat_sample, generator, 'cuda', H=np.expand_dims(R_test[30,:,:], axis=0), iterations = 200)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_576127/2037419828.py\u001b[0m in \u001b[0;36mmodel_eval_ML\u001b[0;34m(NT, snr_min, snr_max, batch_size, repeat_sample, generator, device, Cu, H, iterations)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0mshatBatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mml_proc_star\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhBatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myBatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0mshatBatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlSolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigConst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0mSER_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msym_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshatBatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_QAM_const\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimag_QAM_const\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0macum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mSER_final\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MIMO_detection_project/classic_detectors.py\u001b[0m in \u001b[0;36mmlSolver\u001b[0;34m(hBatch, yBatch, Symb)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhBatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mimo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSymb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddVars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGRB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBINARY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Z'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Model' is not defined"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "size_sample = repeat_sample * test_batch_size\n",
    "generator = sample_generator(size_sample, mod_n, NR)\n",
    "\n",
    "\n",
    "batch_size = 100\n",
    "time_seq = 5\n",
    "H0 = torch.empty((batch_size, 2 * NR, 2 * NT))\n",
    "H1 = torch.empty((batch_size, 2 * NR, 2 * NT))\n",
    "H2 = torch.empty((batch_size, 2 * NR, 2 * NT))\n",
    "H3 = torch.empty((batch_size, 2 * NR, 2 * NT))\n",
    "H4 = torch.empty((batch_size, 2 * NR, 2 * NT))\n",
    "\n",
    "with open(PATH + '/H_test', 'rb') as fp:\n",
    "    H = pkl.load(fp)\n",
    "for ii in range(0, batch_size):\n",
    "    H0[ii] = H[0 + ii * time_seq:1 + ii*time_seq,:,:]\n",
    "    H1[ii] = H[1 + ii * time_seq:2 + ii*time_seq,:,:]\n",
    "    H2[ii] = H[2 + ii * time_seq:3 + ii*time_seq,:,:]\n",
    "    H3[ii] = H[3 + ii * time_seq:4 + ii*time_seq,:,:]\n",
    "    H4[ii] = H[4 + ii * time_seq:5 + ii*time_seq,:,:]\n",
    "    \n",
    "H = H0.repeat_interleave(5, dim=0).to(device=device)\n",
    "\n",
    "    \n",
    "accs_ZF = []\n",
    "accs_ZF.append(model_eval_ML(NT, snrdb_list[NT][0], snrdb_list[NT][-1], 500, 1, generator, 'cuda', H = H.double(), iterations = 500))\n",
    "# accs_ML = model_eval_ML(NT, snrdb_list[NT][0], snrdb_list[NT][-1], 1, repeat_sample, generator, 'cuda', H=np.expand_dims(R_test[30,:,:], axis=0), iterations = 200)\n",
    "\n",
    "# accs_ZF = model_eval_blast(NT, snrdb_classical_list[NT][0], snrdb_classical_list[NT][-1], test_batch_size, generator, 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/nicolas/MIMO_detection_project/results/H_seq_ZF_5hops_true', 'wb') as fp:\n",
    "    pkl.dump(accs_ZF, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SERZF = []\n",
    "SERMMSE = []\n",
    "SERML = []\n",
    "SNR = []\n",
    "\n",
    "for ii in range(len(accs_MMSE)):\n",
    "    SERZF.append(accs_MMSE[ii][1])\n",
    "#     SERMMSE.append(accs_MMSE[ii][1])\n",
    "#     SERML.append(accs_ML[ii][1])\n",
    "    SNR.append(accs_MMSE[ii][0])\n",
    "    \n",
    "plt.semilogy(SNR, SERZF, label = 'ZF')   \n",
    "# plt.semilogy(SNR, SERMMSE, label = 'MMSE')   \n",
    "# plt.semilogy(SNR, SERML, label = 'ML')   \n",
    "plt.legend()\n",
    "# plt.xlim([10, 17])\n",
    "# SER_HYPER_MLPDense_Hdaga_TORCH = SER\n",
    "# %store SER_HYPER_MLPDense_Hdaga_TORCH\n",
    "# k = 9\n",
    "# SER_HYPER_GNN_TORCH[:,k] = SER\n",
    "# plt.semilogy(np.multiply(np.mean(SER_HYPER_GNN_TORCH[:,0:k+1], axis=1),1),marker='*',color='b',label='HyperMIMO-GNN')\n",
    "# SER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/home/nicoz/MMNet-tests/learning_based/Torch/Results/Test_set2_15samples/ZF_result_testSet2_15samples', 'wb') as fp:\n",
    "#     pickle.dump(accs_ZF, fp)\n",
    "\n",
    "with open('/home/nicolas/MIMO_detection_project/results/H_seq_MMSE_5hops', 'wb') as fp:\n",
    "    pkl.dump(accs_MMSE, fp)\n",
    "    \n",
    "# with open('/home/nicoz/MMNet-tests/learning_based/Torch/Results/ML_6t24r_result_testSet2', 'wb') as fp:\n",
    "#     pickle.dump(accs_ML, fp)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = sample_generator(25000, mod_n, NT)\n",
    "\n",
    "H = torch.tensor(R)\n",
    "H = H.repeat_interleave(repeat_sample, dim=0)\n",
    "# H.shape\n",
    "y, x, j_indices, noise_sigma = generator.give_batch_data_Hinput(H, NT, snr_db_min=7, snr_db_max=7, batch_size= (25000))\n",
    "\n",
    "    #         H, y, x, j_indices, no# y = y.to(device=device)\n",
    "# x = x.to(device=device)\n",
    "# j_indices = j_indices.to(device=device)        \n",
    "# noise_sigma = noise_sigma.to(device=device)\n",
    "# #         y_zf = batch_matvec_mul(H_inv, y)\n",
    "\n",
    "\n",
    "# y = y.unsqueeze(dim=-1).numpy()\n",
    "# H = H.numpy()\n",
    "# const = generator.constellation\n",
    "\n",
    "# shatBatch, status = mlSolver(H, y, sigConst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_snrdB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.QAM_const()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = generator.modulate(generator.random_indices(NT, train_batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = sample_generator(train_batch_size, mod_n, NT)\n",
    "const = generator.constellation\n",
    "indices = generator.random_indices(NT, train_batch_size)\n",
    "x = generator.modulate(indices)\n",
    "y, noise_sigma, actual_snrdB = generator.channel(R, x, 0, 10, NT, train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = permuteBatchMatrix(R, test_batch_size, 2 * NT, device='cuda').double()\n",
    "generator = sample_generator(train_batch_size, mod_n, NT)\n",
    "const = generator.constellation\n",
    "indices = generator.random_indices(NT, train_batch_size)\n",
    "x = generator.modulate(indices)\n",
    "y, noise_sigma, actual_snrdB = generator.channel(R, x, 0, 10, NT, train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(7, 18, 18-7+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCu(NT = 6, NR = 12):\n",
    "    \n",
    "    phi = np.zeros((10,6))\n",
    "\n",
    "    phi_mean = np.linspace(-50,50,6)\n",
    "\n",
    "    phi[:,0] = np.random.normal(phi_mean[0], 10, 10)\n",
    "    phi[:,1] = np.random.normal(phi_mean[1], 10, 10)\n",
    "    phi[:,2] = np.random.normal(phi_mean[2], 10, 10)\n",
    "    phi[:,3] = np.random.normal(phi_mean[3], 10, 10)\n",
    "    phi[:,4] = np.random.normal(phi_mean[4], 10, 10)\n",
    "    phi[:,5] = np.random.normal(phi_mean[5], 10, 10)\n",
    "\n",
    "    j = complex(0,1)\n",
    "\n",
    "    d = 1 / 2\n",
    "    Cu = np.zeros((NR, NR, NT),dtype=complex)\n",
    "    for uu in range(NT):\n",
    "        for mm in range(NR):\n",
    "            for nn in range(NR):\n",
    "                Cu[mm,nn,uu] = np.exp(2 * np.pi * j * d * (mm-nn) * np.sin((phi[0,uu] * np.pi)/180))\\\n",
    "                            * np.exp (-((10*np.pi)/180)**2/2 * (2 * np.pi * d * (mm-nn) * np.cos((phi[0,uu] * np.pi)/180))**2 )\n",
    "\n",
    "    return Cu\n",
    "\n",
    "def createH(Cu, batch_size):\n",
    "    H = np.zeros((batch_size, NR, NT), dtype=complex)\n",
    "    auxHTH = np.zeros((batch_size, NT, NT ))\n",
    "    HTH = np.zeros((batch_size, 2 * NT, 2 * NT))\n",
    "\n",
    "    for ii in range(batch_size):\n",
    "        for uu in range(NT):\n",
    "            lamb, v = LA.eig(Cu[:,:,uu])\n",
    "            e = np.random.multivariate_normal(np.zeros(2 * NR), 0.5*np.eye(2 * NR),1).view(np.complex128)[0]\n",
    "\n",
    "            H[ii,:,uu] = np.dot(np.matmul(np.matmul(v,np.diag(np.sqrt(lamb))),np.transpose(np.conj(v))),e).ravel()\n",
    "\n",
    "        auxHTH = np.matmul(np.transpose(np.conj(H[ii,:,:])), H[ii,:,:])\n",
    "        h1 = np.concatenate([np.real(auxHTH), -1. * np.imag(auxHTH)], axis=1)\n",
    "        h2 = np.concatenate([np.imag(auxHTH), np.real(auxHTH)], axis=1)\n",
    "        HTH[ii,:,:] = np.concatenate([h1, h2], axis=0)\n",
    "\n",
    "\n",
    "    return np.float64(HTH)\n",
    "\n",
    "def createQR(Cu, batch_size, NT = 6, NR = 12):\n",
    "    e = torch.empty((batch_size, 2 * NR)).normal_(mean=0.0, std=1./np.sqrt(2.))\n",
    "    \n",
    "    for uu in range(NT):\n",
    "        \n",
    "#     HH = np.zeros((batch_size, NR, NT), dtype=complex)\n",
    "#     aux = np.zeros((batch_size, 2 * NR, 2 * NR ))\n",
    "#     batchQ = np.zeros((batch_size, 2 * NT,2 * NR ))\n",
    "#     batchR = np.zeros((batch_size, 2 * NT,2 * NT ))\n",
    "#     QQ = np.zeros((NR, NT), dtype=complex)\n",
    "#     RR = np.zeros((NT, NT), dtype=complex)\n",
    "#     for ii in range(batch_size):\n",
    "#         for uu in range(NT):\n",
    "#             lamb, v = LA.eig(Cu[:,:,uu])\n",
    "#             e = np.random.multivariate_normal(np.zeros(2 * NR), 0.5*np.eye(2 * NR),1).view(np.complex128)[0]\n",
    "\n",
    "#             HH[ii,:,uu] = np.dot(np.matmul(np.matmul(v,np.diag(np.sqrt(lamb))),np.transpose(np.conj(v))),e).ravel()\n",
    "\n",
    "#         QQ[:,:],RR[:,:] = np.linalg.qr(HH[ii,:,:])\n",
    "\n",
    "\n",
    "#         QQtr = np.transpose(np.conjugate(QQ)) \n",
    "#         q1 = np.concatenate([np.real(QQtr), -1. * np.imag(QQtr)], axis=1)\n",
    "#         q2 = np.concatenate([np.imag(QQtr), np.real(QQtr)], axis=1)\n",
    "#         r1 = np.concatenate([np.real(RR), -1. * np.imag(RR)], axis=1)\n",
    "#         r2 = np.concatenate([np.imag(RR), np.real(RR)], axis=1)\n",
    "#         batchQ[ii,:,:] = np.concatenate([q1, q2], axis=0)\n",
    "#         batchR[ii,:,:] = np.concatenate([r1, r2], axis=0)\n",
    "\n",
    "    return np.float64(batchQ), np.float64(batchR), np.float64(HH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = sample_generator(validtn_batch_size, mod_n, NR)\n",
    "test(generator)\n",
    "print('******************************** Now Testing **********************************************')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import os\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from collections import defaultdict\n",
    "from classic_detectors import blast_eval, sym_detection\n",
    "\n",
    "# Parameters\n",
    "NR = 64\n",
    "mod_n = 16\n",
    "d_transmitter_encoding = 32\n",
    "d_model = 512\n",
    "n_head = 10\n",
    "nhid = d_model*4 + 4*2*mod_n\n",
    "nlayers = 10\n",
    "dropout = 0.0\n",
    "\n",
    "# Batch sizes for training and validation sets\n",
    "validtn_batch_size = 5000\n",
    "validtn_iter = 2000\n",
    "\n",
    "M = int(np.sqrt(mod_n))\n",
    "sigConst = np.linspace(-M+1, M-1, M) \n",
    "sigConst /= np.sqrt((sigConst ** 2).mean())\n",
    "sigConst /= np.sqrt(2.) #Each complex transmitted signal will have two parts\n",
    "\n",
    "validtn_NT_list = np.asarray([16, 32])\n",
    "snrdb_classical_list = {16:np.arange(9.0, 15.0), 32:np.arange(11.0, 17.0)}\n",
    "\n",
    "\n",
    "blast_validtn_filename = './final_results/blast_validtn_results.pickle'\n",
    "\n",
    "def accuracy(out, j_indices):\n",
    "\tout = out.permute(1,2,0)\n",
    "\tout = out.argmax(dim=1)\n",
    "\taccuracy = (out == j_indices).sum().to(dtype=torch.float32)\n",
    "\treturn accuracy.item()/out.numel()\n",
    "\n",
    "def bit_indices(indices, mod_n):\n",
    "\treal_indices = (indices//np.sqrt(mod_n)).to(dtype=torch.int32)\n",
    "\timag_indices = (indices%np.sqrt(mod_n)).to(dtype=torch.int32)\n",
    "\tjoint_bit_indices = torch.cat((real_indices, imag_indices), dim=-1)\n",
    "\treturn joint_bit_indices\n",
    "\n",
    "def sym_accuracy(out, j_indices):\n",
    "\taccuracy = (out == j_indices).sum().to(dtype=torch.float32)\n",
    "\treturn accuracy.item()/out.numel()\n",
    "\n",
    "def bit_accuracy(out, j_indices):\n",
    "\tbit_out_indices = bit_indices(out, mod_n)\n",
    "\tbit_j_indices = bit_indices(j_indices, mod_n)\n",
    "\treturn sym_accuracy(bit_out_indices, bit_j_indices)\n",
    "\n",
    "def generate_big_validtn_data(generator, batch_size):\n",
    "\tvalidtn_data_dict = {int(NT):{} for NT in validtn_NT_list}\n",
    "\tfor NT in validtn_NT_list:\n",
    "\t\tfor snr in snrdb_classical_list[NT]:\n",
    "\t\t\tbig_validtn_H, big_validtn_y, big_validtn_x, big_validtn_j_indices, big_noise_sigma = generator.give_batch_data(int(NT), snr_db_min=snr, snr_db_max=snr, batch_size=batch_size)\n",
    "\t\t\tvalidtn_data_dict[int(NT)][snr] = (big_validtn_H, big_validtn_y , big_validtn_j_indices, big_noise_sigma)\n",
    "\treturn validtn_data_dict\n",
    "\n",
    "def validate_blast_given_data(H, y, big_validtn_j_indices, noise_sigma, NT, real_QAM_const, imag_QAM_const):\n",
    "\n",
    "\t# Numpy modifications for classical Symbol detection algorithms\n",
    "\ty = y.unsqueeze(dim=-1).numpy()\n",
    "\tH = H.numpy()\n",
    "\n",
    "\tresults_blast = blast_eval(y, H, sigConst, NT, NR).squeeze()\n",
    "\tindices_blast = sym_detection(torch.from_numpy(results_blast), real_QAM_const, imag_QAM_const)\n",
    "\n",
    "\tblast_accr = sym_accuracy(indices_blast, big_validtn_j_indices)\n",
    "\treturn blast_accr\n",
    "\n",
    "\n",
    "def validate_classical(generator, real_QAM_const, imag_QAM_const, save_result=True):\n",
    "\n",
    "\tblast_result_dict = {int(NT):defaultdict(float) for NT in validtn_NT_list}\n",
    "\tfor iter in range(validtn_iter):\n",
    "\t\tvalidtn_data_dict = generate_big_validtn_data(generator, validtn_batch_size)\n",
    "\t\tfor NT in validtn_NT_list:\n",
    "\t\t\tfor snr in snrdb_classical_list[NT]:\n",
    "\t\t\t\tprint(NT, snr)\n",
    "\t\t\t\tbig_validtn_H, big_validtn_y, big_validtn_j_indices, big_noise_sigma = validtn_data_dict[NT][snr]\n",
    "\t\t\t\taccr = validate_blast_given_data(big_validtn_H, big_validtn_y, big_validtn_j_indices, big_noise_sigma, NT, real_QAM_const, imag_QAM_const)\n",
    "\t\t\t\tblast_result_dict[NT][snr] = blast_result_dict[NT][snr] + (accr-blast_result_dict[NT][snr])/float(iter+1.0)\n",
    "\n",
    "\t\tif (save_result):\n",
    "\t\t\twith open(blast_validtn_filename, 'wb') as handle:\n",
    "\t\t\t\tpickle.dump(blast_result_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\t\t\tprint('Intermediate Test results saved at : ', blast_validtn_filename)\n",
    "\n",
    "\t\tprint('blast results : ', blast_result_dict)\n",
    "\n",
    "\n",
    "def test(generator):\n",
    "\tvalidate_classical(generator, generator.real_QAM_const, generator.imag_QAM_const, True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigConst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
